{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import torch\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"csv_agile_H_Southern_England.csv\", header=None)\n",
    "df = df.rename(columns={\n",
    "    0:\"date\",\n",
    "    1:\"time\",\n",
    "    4:\"cost\"\n",
    "})\n",
    "df = df[[\"date\",\"time\", \"cost\"]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0.13596258262511804\n"
     ]
    }
   ],
   "source": [
    "#Training dataset\n",
    "df_train = df[df.date<='2022-01-01'] #before 2022\n",
    "#Test dataset\n",
    "df_test =  df[df.date>'2022-01-01'] # after 2022\n",
    "\n",
    "print(\"test\", len(df_test) / (len(df_train)+len(df_train)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                       date   time      cost\n67776  2022-01-01T00:00:00Z  00:00  16.53750\n67777  2022-01-01T00:30:00Z  00:30  16.53750\n67778  2022-01-01T01:00:00Z  01:00  20.10750\n67779  2022-01-01T01:30:00Z  01:30  10.58400\n67780  2022-01-01T02:00:00Z  02:00  15.43500\n...                     ...    ...       ...\n86201  2023-01-19T20:30:00Z  20:30  32.86500\n86202  2023-01-19T21:00:00Z  21:00  31.97250\n86203  2023-01-19T21:30:00Z  21:30  29.78850\n86204  2023-01-19T22:00:00Z  22:00  34.22601\n86205  2023-01-19T22:30:00Z  22:30  28.77000\n\n[18430 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>time</th>\n      <th>cost</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>67776</th>\n      <td>2022-01-01T00:00:00Z</td>\n      <td>00:00</td>\n      <td>16.53750</td>\n    </tr>\n    <tr>\n      <th>67777</th>\n      <td>2022-01-01T00:30:00Z</td>\n      <td>00:30</td>\n      <td>16.53750</td>\n    </tr>\n    <tr>\n      <th>67778</th>\n      <td>2022-01-01T01:00:00Z</td>\n      <td>01:00</td>\n      <td>20.10750</td>\n    </tr>\n    <tr>\n      <th>67779</th>\n      <td>2022-01-01T01:30:00Z</td>\n      <td>01:30</td>\n      <td>10.58400</td>\n    </tr>\n    <tr>\n      <th>67780</th>\n      <td>2022-01-01T02:00:00Z</td>\n      <td>02:00</td>\n      <td>15.43500</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>86201</th>\n      <td>2023-01-19T20:30:00Z</td>\n      <td>20:30</td>\n      <td>32.86500</td>\n    </tr>\n    <tr>\n      <th>86202</th>\n      <td>2023-01-19T21:00:00Z</td>\n      <td>21:00</td>\n      <td>31.97250</td>\n    </tr>\n    <tr>\n      <th>86203</th>\n      <td>2023-01-19T21:30:00Z</td>\n      <td>21:30</td>\n      <td>29.78850</td>\n    </tr>\n    <tr>\n      <th>86204</th>\n      <td>2023-01-19T22:00:00Z</td>\n      <td>22:00</td>\n      <td>34.22601</td>\n    </tr>\n    <tr>\n      <th>86205</th>\n      <td>2023-01-19T22:30:00Z</td>\n      <td>22:30</td>\n      <td>28.77000</td>\n    </tr>\n  </tbody>\n</table>\n<p>18430 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67649, 128)\n",
      "(18303, 128)\n"
     ]
    }
   ],
   "source": [
    "length = 128 #length of sequence\n",
    "\n",
    "#Sliding Window\n",
    "def sliding_window(array):\n",
    "    window_step = 1\n",
    "    window_size = 128 #2.6 days\n",
    "    return np.lib.stride_tricks.sliding_window_view(array, window_size)\n",
    "\n",
    "train = sliding_window(df_train[\"cost\"].to_numpy())\n",
    "test = sliding_window(df_test[\"cost\"].to_numpy())\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define RNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#Define RNN Model\n",
    "#https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "hidden_size = 10\n",
    "num_layers = 5\n",
    "activation = \"relu\" #relu or tanh\n",
    "bidirectional = False\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.rnn = torch.nn.RNN(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=0.1,\n",
    "            nonlinearity=activation,\n",
    "            bidirectional=bidirectional,\n",
    "            batch_first=False\n",
    "        )\n",
    "        # compress output to the same dim as y\n",
    "        self.linear = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_prev):\n",
    "        out, hidden_prev = self.rnn(x, hidden_prev) # [1, seq, h] => [seq, h]  (batch=1)\n",
    "        out = out.reshape(-1, hidden_size)  # stack batch and seq\n",
    "\n",
    "        # linear layer so that output is not [seq,h] but [seq, 1]\n",
    "        # so it is comparable with y, for loss calculation\n",
    "        out = self.linear(out)  # [seq, h] => [seq, 1]\n",
    "        out = out.unsqueeze(dim=0)  # => [1, seq, 1]\n",
    "        return out, hidden_prev\n",
    "\n",
    "rnn = Net()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)\n",
    "\n",
    "# rnn= torch.nn.RNN(input_size=input_size, hidden_size=hidden_size,num_layers=num_layers,\n",
    "#                   dropout=0, nonlinearity=\"relu\", bidirectional=bidirectional)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# input = torch.randn(length,batch_size,input_size)\n",
    "\n",
    "\n",
    "\n",
    "# out, hidden = rnn(input, h0)\n",
    "# print(out.shape, hidden.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# input = torch.randn(length,batch_size,input_size)\n",
    "# h0 = torch.randn(num_layers,batch_size,hidden_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  35.37954330444336\n",
      "Loss:  38.498287200927734\n",
      "Loss:  37.53645324707031\n",
      "Loss:  37.70008850097656\n",
      "Loss:  27.05722427368164\n",
      "Loss:  29.23897933959961\n",
      "Loss:  37.45521545410156\n",
      "Loss:  37.253265380859375\n",
      "Loss:  35.400325775146484\n",
      "Loss:  27.051958084106445\n",
      "Loss:  31.791528701782227\n",
      "Loss:  37.247589111328125\n",
      "Loss:  37.41933059692383\n",
      "Loss:  34.86930847167969\n",
      "Loss:  27.3126277923584\n",
      "Loss:  39.187530517578125\n",
      "Loss:  39.53559494018555\n",
      "Loss:  39.66175842285156\n",
      "Loss:  33.07939910888672\n",
      "Loss:  29.947664260864258\n",
      "Loss:  40.384429931640625\n",
      "Loss:  40.80271530151367\n",
      "Loss:  41.33481216430664\n",
      "Loss:  29.96868324279785\n",
      "Loss:  29.92669105529785\n",
      "Loss:  40.622920989990234\n",
      "Loss:  40.37743377685547\n",
      "Loss:  39.62628173828125\n",
      "Loss:  26.96959686279297\n",
      "Loss:  29.174301147460938\n",
      "Loss:  36.78670883178711\n",
      "Loss:  35.637691497802734\n",
      "Loss:  34.22279357910156\n",
      "Loss:  25.68470001220703\n",
      "Loss:  32.2880973815918\n",
      "Loss:  36.936241149902344\n",
      "Loss:  36.6348876953125\n",
      "Loss:  35.145565032958984\n",
      "Loss:  31.216218948364258\n",
      "Loss:  41.77971649169922\n",
      "Loss:  41.746726989746094\n",
      "Loss:  41.463470458984375\n",
      "Loss:  47.7569580078125\n",
      "Loss:  61.19295883178711\n",
      "Loss:  73.24288177490234\n",
      "Loss:  79.21748352050781\n",
      "Loss:  78.83585357666016\n",
      "Loss:  74.54349517822266\n",
      "Loss:  71.35183715820312\n",
      "Loss:  72.82726287841797\n",
      "Loss:  74.59235382080078\n",
      "Loss:  82.34808349609375\n",
      "Loss:  80.2664794921875\n",
      "Loss:  80.95130157470703\n",
      "Loss:  82.32959747314453\n",
      "Loss:  77.88658905029297\n",
      "Loss:  62.42989730834961\n",
      "Loss:  39.04446029663086\n",
      "Loss:  43.983619689941406\n",
      "Loss:  49.10238265991211\n",
      "Loss:  51.50009536743164\n",
      "Loss:  47.78794479370117\n",
      "Loss:  37.22966384887695\n",
      "Loss:  44.77641296386719\n",
      "Loss:  44.08906173706055\n",
      "Loss:  44.38157272338867\n",
      "Loss:  33.464149475097656\n",
      "Loss:  28.777753829956055\n",
      "Loss:  38.59572982788086\n",
      "Loss:  38.914794921875\n",
      "Loss:  39.66183090209961\n",
      "Loss:  25.447935104370117\n",
      "Loss:  25.498544692993164\n",
      "Loss:  35.99565887451172\n",
      "Loss:  36.25273513793945\n",
      "Loss:  35.9668083190918\n",
      "Loss:  27.461427688598633\n",
      "Loss:  29.91884994506836\n",
      "Loss:  36.550533294677734\n",
      "Loss:  38.09105682373047\n",
      "Loss:  37.17426681518555\n",
      "Loss:  27.79109764099121\n",
      "Loss:  31.40394401550293\n",
      "Loss:  36.876155853271484\n",
      "Loss:  36.969093322753906\n",
      "Loss:  34.01633834838867\n",
      "Loss:  25.53676414489746\n",
      "Loss:  36.11117935180664\n",
      "Loss:  36.29264831542969\n",
      "Loss:  37.06682205200195\n",
      "Loss:  29.635953903198242\n",
      "Loss:  26.85501480102539\n",
      "Loss:  37.86457824707031\n",
      "Loss:  37.724613189697266\n",
      "Loss:  37.09408950805664\n",
      "Loss:  29.348684310913086\n",
      "Loss:  28.867027282714844\n",
      "Loss:  45.79084396362305\n",
      "Loss:  44.434898376464844\n",
      "Loss:  45.021324157714844\n",
      "Net(\n",
      "  (rnn): RNN(1, 10, num_layers=5, dropout=0.1)\n",
      "  (linear): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1 #number of batches for training\n",
    "\n",
    "def train_rnn(rnn, n_steps, print_every):\n",
    "\n",
    "\n",
    "    # hidden = h0\n",
    "    # hidden = torch.randn(num_layers,batch_size,hidden_size)\n",
    "\n",
    "    # initialize the hidden state\n",
    "    if bidirectional:\n",
    "        hidden = torch.zeros(2*num_layers,batch_size,hidden_size)\n",
    "    else:\n",
    "        hidden = torch.zeros(num_layers,batch_size,hidden_size)\n",
    "\n",
    "    for batch_i, step in enumerate(range(n_steps)):\n",
    "        # defining the training data\n",
    "        # time_steps = np.linspace(step * np.pi, (step+1)*np.pi, length + 1)\n",
    "        # data = np.sin(time_steps)\n",
    "        # data.resize((length + 1, 1)) # input_size=1\n",
    "        #\n",
    "        # x = data[:-1]\n",
    "        # y = data[1:]\n",
    "        #\n",
    "        # x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
    "        # y_tensor = torch.Tensor(y)\n",
    "        #\n",
    "        # print(x_tensor.shape)\n",
    "\n",
    "        # input = torch.randn(length,batch_size,input_size)\n",
    "\n",
    "        # x: 49 points 0-49; y: 49 points 1-50\n",
    "        data=train[batch_i]\n",
    "        x = torch.tensor(data[:-1]).float().reshape(length - 1, 1, 1)  # [seq_len, b, fea_len]\n",
    "        y = torch.tensor(data[1:]).float().reshape(length - 1, 1, 1)  # [seq_len, b, fea_len]\n",
    "\n",
    "        # outputs from the rnn\n",
    "        # print(x.shape)\n",
    "        # print(hidden.shape)\n",
    "        prediction, hidden = rnn(x, hidden)\n",
    "\n",
    "        # Representing Memory #\n",
    "        # make a new variable for hidden and detach the hidden state from its history\n",
    "        # this way, we don't backpropagate through the entire history\n",
    "        hidden = hidden.data\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(prediction, y)\n",
    "\n",
    "        # zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        # perform backprop and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # display loss and predictions\n",
    "        if batch_i%print_every == 0:\n",
    "            print('Loss: ', loss.item())\n",
    "            # plt.plot(input[1:], x, 'r.') # input\n",
    "            # plt.plot(input[1:], prediction.data.numpy().flatten(), 'b.') # predictions\n",
    "            # plt.show()\n",
    "    return rnn\n",
    "\n",
    "rnn = train_rnn(rnn, 1000, 10)\n",
    "\n",
    "print(rnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(585.3307, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if bidirectional:\n",
    "    hidden = torch.zeros(2*num_layers,batch_size,hidden_size)\n",
    "else:\n",
    "    hidden = torch.zeros(num_layers,batch_size,hidden_size)\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "for batch_i in range(len(test)):\n",
    "    data=test[batch_i]\n",
    "    x = torch.tensor(data[:-1]).float().reshape(length - 1, 1, 1)  # [seq_len, b, fea_len]\n",
    "    y = torch.tensor(data[1:]).float().reshape(length - 1, 1, 1)  # [seq_len, b, fea_len]\n",
    "\n",
    "    prediction, hidden = rnn(x, hidden)\n",
    "    hidden = hidden.data\n",
    "    total_loss += criterion(prediction, y)\n",
    "\n",
    "print(total_loss / len(test))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}